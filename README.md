# Poem-summarization-using-t5-and-BART
**Poem Summarization using T5 and BART** involves applying two of the most advanced transformer-based models—T5 (Text-To-Text Transfer Transformer) and BART (Bidirectional and Auto-Regressive Transformers)—to summarize poetic texts. These models, both designed for text generation and understanding tasks, can handle the nuanced language, structure, and metaphorical expressions found in poetry.

1. **T5** works by converting all natural language tasks into a text-to-text format, allowing it to interpret a poem and generate a concise summary based on the meaning and theme of the original text.
   
2. **BART**, designed for sequence-to-sequence tasks like summarization, uses a bidirectional encoder (like BERT) to understand the full context of a poem and an autoregressive decoder (like GPT) to generate the output, summarizing the key aspects of the poem while preserving its literary essence.

The summarization process focuses on maintaining the emotional depth, thematic core, and stylistic elements while condensing the poem's content. 
